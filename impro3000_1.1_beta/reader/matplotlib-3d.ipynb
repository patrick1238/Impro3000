{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ever tried to visualize 3D images using Python? It sounds like something that would come up frequently when using things like medical scanner data, but it's not super well documented. One way to go about it is display 2D slides, possibly interactively. [DataCamp has a good tutorial on how to do this](https://www.datacamp.com/community/tutorials/matplotlib-3d-volumetric-data), but what if you can't use a dynamic image? For instance, for a printed publication, a static image is your only option.\n",
    "\n",
    "For this tutorial, you'll need the [requests](http://docs.python-requests.org/en/master/) library to get the data, [nibabel](http://nipy.org/nibabel/) to read the images, [numpy](http://www.numpy.org/) and [scikit-image](http://scikit-image.org/) for various manipulation tasks, and of course [matplotlib](https://matplotlib.org/) for the actual plotting. You can get all of this by running\n",
    "\n",
    "    pip install requests nibabel numpy scikit-image matplotlib\n",
    "    \n",
    "Note that I'm using Python 3 here ([as you should be](http://www.python3statement.org/)), but this tutorial should work with minor changes using Python 2. You can check the library versions I've used at the very end of the page.\n",
    "\n",
    "You can also have a peek at the [results](#results) before embarking.\n",
    "\n",
    "\n",
    "# Getting the data\n",
    "\n",
    "We'll use the [Attention to Visual Motion fMRI dataset](http://www.fil.ion.ucl.ac.uk/spm/data/attention/)[^1] for cool brain images. Of course, feel free to visualize whatever you want. As long as you have a 3D numpy array of data, you can skip to the next section to get started on the actual visualizing.\n",
    "\n",
    "Let's start by getting the zip file (79MB):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "images = requests.get('http://www.fil.ion.ucl.ac.uk/spm/download/data/attention/attention.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid cluttering the filesystem, let's keep the zip archive in memory. We're using [`BytesIO`](https://docs.python.org/3/library/io.html#io.BytesIO), which, like its cousin [`StringIO`](https://docs.python.org/3/library/io.html#io.StringIO), is a essentially a way to equip a `bytes` (or `string`) object with file I/O operations (such as `read`, `write` and `seek`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "zipstream = BytesIO(images.content)\n",
    "zf = zipfile.ZipFile(zipstream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This zip file contains a number of images in [Analyze](https://en.wikipedia.org/wiki/Analyze_(imaging_software)) format. It's easy to open an image with nibabel: just run `nibabel.load(filename)`. Unfortunately, a single Analyze-formatted image consists of a header file (`.hdr`) and a separate file for the data itself (`.img`). If the images are stored on disk, `nibabel.load` will automatically find both files, but this doesn't work here.\n",
    "\n",
    "With a little trickery, though, we can get `nibabel` to load the image directly from memory. `img.get_data()` gets us the 3D data array, and we can get started with plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nibabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b14140b6cfcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFileHolder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnibabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAnalyzeImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'attention/structural/nsM00587_0002.hdr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'attention/structural/nsM00587_0002.img'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nibabel'"
     ]
    }
   ],
   "source": [
    "from nibabel import FileHolder\n",
    "from nibabel.analyze import AnalyzeImage\n",
    "\n",
    "header = BytesIO(zf.open('attention/structural/nsM00587_0002.hdr').read())\n",
    "image = BytesIO(zf.open('attention/structural/nsM00587_0002.img').read())\n",
    "img = AnalyzeImage.from_file_map({'header': FileHolder(fileobj=header), 'image': FileHolder(fileobj=image)})\n",
    "arr = img.get_data()\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first look\n",
    "\n",
    "Let's first do a regular plot of a horizontal slice of our brain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(arr[:,:,5])\n",
    "plt.colorbar()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My knowledge of neurology is severely limited, but I'm pretty sure those are eye sockets on the right!\n",
    "\n",
    "If you look at the colorbar, you'll realize that there are very few points that reach the top values (larger than, say, 1500). We can confirm that insight by making a histogram:\n",
    "\n",
    "(BTW, we're using the default [Viridis](https://bids.github.io/colormap/) colorscheme, which was designed to solve a number of ergonomic problems with Jet, the former default. [There's an interesting talk about its design process (video)](https://www.youtube.com/watch?v=xAoljeRJ3lU).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "\n",
    "def normalize(arr):\n",
    "    arr_min = np.min(arr)\n",
    "    return (arr-arr_min)/(np.max(arr)-arr_min)\n",
    "\n",
    "def show_histogram(values):\n",
    "    n, bins, patches = plt.hist(values.reshape(-1), 50, normed=1)\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "    for c, p in zip(normalize(bin_centers), patches):\n",
    "        plt.setp(p, 'facecolor', cm.viridis(c))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "show_histogram(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to change this using a homebrewed and totally guesstimated transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_by(arr, fac):\n",
    "    mean = np.mean(arr)\n",
    "    return (arr-mean)*fac + mean\n",
    "\n",
    "transformed = np.clip(scale_by(np.clip(normalize(arr)-0.1, 0, 1)**0.4, 2)-0.1, 0, 1)\n",
    "show_histogram(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of colors is more uniform, with a big peak at 0 (which we'll see is a good idea).\n",
    "\n",
    "# Plotting!\n",
    "\n",
    "## Warmup: a pile of cubes\n",
    "\n",
    "Matplotlib's 3D capabilities are still being developed, and they have a few quirks we'll have to work around. Let's forget our brain for a moment, and start with a very simple [voxel](https://en.wikipedia.org/wiki/Voxel) plot, to introduce basic concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "def make_ax(grid=False):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"z\")\n",
    "    ax.grid(grid)\n",
    "    return ax\n",
    "\n",
    "filled = np.array([\n",
    "    [[1, 0, 1], [0, 0, 1], [0, 1, 0]],\n",
    "    [[0, 1, 1], [1, 0, 0], [1, 0, 1]],\n",
    "    [[1, 1, 0], [1, 1, 1], [0, 0, 0]]\n",
    "])\n",
    "\n",
    "ax = make_ax(True)\n",
    "ax.voxels(filled, edgecolors='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can display some voxels easily enough (in case you don't know what they are and for some reason haven't clicked the Wikipedia link above, they're just 3D pixels, so little cubes).\n",
    "\n",
    "Here, the `filled` array tells matplotlib which voxels to fill in. Any truthy value (you'll most likely use `True` or `1`) in the array means that the voxel in the corresponding poxition should be filled. It's in `x`-major, `z`-minor order, so the first `[1, 0, 1]` block, for instance, means \"fill in the blocks at (x, y, z)=(0, 0, 0) don't fill the one at (0, 0, 1), and fill the one at (0, 0, 2)\".\n",
    "\n",
    "That's all good, but the blocks in front tend to occlude the rest. How about we make everything semi-transparent? We can do this by specifying an HTML color with an alpha component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = make_ax()\n",
    "ax.voxels(filled, facecolors='#1f77b430', edgecolors='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to work (although it's a bit messy), but there's a problem. Look at what happens if we display a solid block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = make_ax()\n",
    "ax.voxels(np.ones((3, 3, 3)), facecolors='#1f77b430', edgecolors='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the faces and edges on the sides are rendered. This seems okay, but what if we want to color the middle voxel red, it's not going to show:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = make_ax()\n",
    "colors = np.array([[['#1f77b430']*3]*3]*3)\n",
    "colors[1,1,1] = '#ff0000ff'\n",
    "ax.voxels(np.ones((3, 3, 3)), facecolors=colors, edgecolor='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this, we can add extra voxels in between. Let's define a helper function, `explode`, which will take our `filled` array and return an array twice as large in each dimension, with an extra space between each voxel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explode(data):\n",
    "    shape_arr = np.array(data.shape)\n",
    "    size = shape_arr[:3]*2 - 1\n",
    "    exploded = np.zeros(np.concatenate([size, shape_arr[3:]]), dtype=data.dtype)\n",
    "    exploded[::2, ::2, ::2] = data\n",
    "    return exploded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that the function supports arrays of more than three dimensions, and will stick any extra dimensions back at the end. This is because we'll later use explode on 4D arrays.)\n",
    "\n",
    "Let's plot the exploded version, without the borders for better visibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = make_ax(True)\n",
    "colors = np.array([[['#1f77b430']*3]*3]*3)\n",
    "colors[1,1,1] = '#ff0000ff'\n",
    "colors = explode(colors)\n",
    "filled = explode(np.ones((3, 3, 3)))\n",
    "ax.voxels(filled, facecolors=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, but we don't want these gaps between the voxels.\n",
    "\n",
    "Fortunately, `voxels` supports one (or rather three) other arguments, `x`, `y` and `z`. These should follow the format generated by [`np.indices`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.indices.html), so they're 4-dimensional. They allow us to change the coordinates of a voxel corner. Specifically, `x[i, j, k]` is the x coordinate of the lower-bottom-left corner of the voxel at position (_i_, _j_, _k_) in the `filled` array. This also mean that if you have _m_ by _n_ by _p_ voxels, `x`, `y` and `z` all have shape (_m+1_, _n+1_, _p+1_).\n",
    "\n",
    "Let's briefly go back to the full block example. We can extend the middle block by incrementing `y` for all blocks in the middle and back columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = make_ax()\n",
    "\n",
    "filled = np.ones((3, 3, 3))\n",
    "x, y, z = np.indices(np.array(filled.shape) + 1)\n",
    "y[:,2:,:] += 4\n",
    "\n",
    "ax.voxels(x, y, z, filled, facecolors='#1f77b430', edgecolor='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could change the coordinates of a specific point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = make_ax()\n",
    "\n",
    "filled = np.ones((3, 3, 3))\n",
    "x, y, z = np.indices(np.array(filled.shape) + 1)\n",
    "x[3, 2, 2] = 5\n",
    "\n",
    "ax.voxels(x, y, z, filled, facecolors='#1f77b430', edgecolor='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all this together, we can draw over all the inserted voxels we just added by making all of the original voxels twice as large. Let's do that, and plot our red cube example again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_coordinates(indices):\n",
    "    x, y, z = indices\n",
    "    x[1::2, :, :] += 1\n",
    "    y[:, 1::2, :] += 1\n",
    "    z[:, :, 1::2] += 1\n",
    "    return x, y, z\n",
    "\n",
    "ax = make_ax()\n",
    "colors = np.array([[['#1f77b430']*3]*3]*3)\n",
    "colors[1,1,1] = '#ff0000ff'\n",
    "colors = explode(colors)\n",
    "filled = explode(np.ones((3, 3, 3)))\n",
    "x, y, z = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "ax.voxels(x, y, z, filled, facecolors=colors, edgecolors='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serious business\n",
    "\n",
    "An important note: `voxels` is slow on large 3D data. I've resized all the brain data to be 50×50×50 voxels, which still has a full runtime of nearly 4 minutes for the entire skull (on my admittedly not very beefy machine). If you have a powerful machine, you can set a higher image size, but remember that it scales cubically. I'm resizing using scikit-image, but there are lots of other options.\n",
    "\n",
    "(Remember that `transformed` is our 3D data, with rescaled values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_DIM = 50\n",
    "\n",
    "from skimage.transform import resize\n",
    "resized = resize(transformed, (IMG_DIM, IMG_DIM, IMG_DIM), mode='constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've dealt with binary data so far, but how can we represent 3D volumetric data with a range of values? The approach I've taken is to set each voxel's transparency equal to its value. In the case of brain data, this allows to see through the black areas corresponding to air around the head, as well as through some of the empty parts inside the brain. Of course, you can't see much trough the brain itself—but the image would be incredibly confusing otherwise. In any case, the technique I'm showing here allows you to adapt the color/transparency system easily should you want to implement something else (for instance, you could set the maximal transparency to a low value, which would make it possible to see through your plot much more).\n",
    "\n",
    "I've replicated `explode` and `expand_coordinates` from above, so you can directly copy-paste the cell below to use in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explode(data):\n",
    "    shape_arr = np.array(data.shape)\n",
    "    size = shape_arr[:3]*2 - 1\n",
    "    exploded = np.zeros(np.concatenate([size, shape_arr[3:]]), dtype=data.dtype)\n",
    "    exploded[::2, ::2, ::2] = data\n",
    "    return exploded\n",
    "\n",
    "def expand_coordinates(indices):\n",
    "    x, y, z = indices\n",
    "    x[1::2, :, :] += 1\n",
    "    y[:, 1::2, :] += 1\n",
    "    z[:, :, 1::2] += 1\n",
    "    return x, y, z\n",
    "\n",
    "def plot_cube(cube, angle=320):\n",
    "    cube = normalize(cube)\n",
    "    \n",
    "    facecolors = cm.viridis(cube)\n",
    "    facecolors[:,:,:,-1] = cube\n",
    "    facecolors = explode(facecolors)\n",
    "    \n",
    "    filled = facecolors[:,:,:,-1] != 0\n",
    "    x, y, z = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "    fig = plt.figure(figsize=(30/2.54, 30/2.54))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.view_init(30, angle)\n",
    "    ax.set_xlim(right=IMG_DIM*2)\n",
    "    ax.set_ylim(top=IMG_DIM*2)\n",
    "    ax.set_zlim(top=IMG_DIM*2)\n",
    "    \n",
    "    ax.voxels(x, y, z, filled, facecolors=facecolors)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes on this implementation:\n",
    "\n",
    " * Instead of colors as strings, I'm using a 4D colors array, where the last dimension (of size 4) holds the red, green, blue, and alpha (transparency) values. Doing `facecolors[:,:,:,-1] = cube` makes the alpha equal to the voxel value.\n",
    " * I'm still using Viridis, the default color map. You can use [any map you like](https://matplotlib.org/users/colormaps.html) that's supported by matplotlib, by changing the call to `cm.viridis`.\n",
    " * I'm setting some axis limits to make sure that all the plots are on the same scales, even if I truncate the image to show a cross-section.\n",
    " * You can add a call to `ax.set_axis_off()` if you want to remove the background and axis ticks.\n",
    "\n",
    "Oh, and if you were wondering, this is where `explode` handling 4D arrays comes in handy.\n",
    "\n",
    "\n",
    "## Results\n",
    "\n",
    "So first, a cut view of the skull:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_cube' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-45e5cd5d8ef8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_cube\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_cube' is not defined"
     ]
    }
   ],
   "source": [
    "plot_cube(resized[:35,::-1,:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I'm plotting the y-axis backwards so that the eyes are in front).\n",
    "\n",
    "A view from the back, cutting through in diagonal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-eb5ec49fe291>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcube\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "cube = np.copy(resized)\n",
    "\n",
    "for x in range(0, IMG_DIM):\n",
    "    for y in range(0, IMG_DIM):\n",
    "        for z in range(max(x-y+5, 0), IMG_DIM):\n",
    "            cube[x, y, z] = 0\n",
    "plot_cube(cube, angle=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a full view, where you can see the nasal cavity and make out the eye sockets at the very bottom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cube(resized[:,::-1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you enjoyed this tutorial! Feel free to drop me suggestions for improvements, questions, or other random notes below. You can also look at [`voxel`'s documentation](https://matplotlib.org/api/_as_gen/mpl_toolkits.mplot3d.axes3d.Axes3D.html#mpl_toolkits.mplot3d.axes3d.Axes3D.voxels) for more details.\n",
    "\n",
    "Here are the library versions I've used for this tutorial:\n",
    "\n",
    "    matplotlib==2.1.0\n",
    "    nibabel==2.2.1\n",
    "    numpy==1.13.3\n",
    "    requests==2.18.4\n",
    "    scikit-image==0.13.1\n",
    "\n",
    "You can also [download the notebook](/content-static/matplotlib-3d/matplotlib-3d.ipynb).\n",
    "\n",
    "[^1]: Büchel, Christian, and K. J. Friston. \"Modulation of connectivity in visual pathways by attention: cortical interactions evaluated with structural equation modelling and fMRI.\" _Cerebral cortex (New York, NY: 1991)_ 7.8 (1997): 768-778."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
